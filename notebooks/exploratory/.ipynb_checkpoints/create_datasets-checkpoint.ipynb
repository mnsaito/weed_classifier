{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets\n",
    "## Data Collection\n",
    "- midwestgardentips.com provides a list of the best performing perennials in the midwest\n",
    "- preen.com provides a list of common weeds state-by-state\n",
    "    - will download a list of common weeds in IL\n",
    "    - will download corresponding photos from the site\n",
    "- garden.org provides a collection of photographs of various plants\n",
    "    - will download photos of both perennials and weeds from this site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# webscrape\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to store data\n",
    "perennial_path = os.path.join(os.pardir, os.pardir, 'data', 'perennials')\n",
    "weed_path = os.path.join(os.pardir, os.pardir, 'data', 'weeds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## midwestgardentips.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape names of best performing perennials from Midwest Gardening site\n",
    "perennial_url = 'https://www.midwestgardentips.com/best-performing-perennials-1'\n",
    "response = get(perennial_url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# Find bolded (i.e., 'strong') and italicized (i.e., 'em') text\n",
    "p_list = [a.text for a in (strong.find('em') for strong in soup.find_all('strong')) if a]\n",
    "\n",
    "perennials = []\n",
    "for i in range(len(p_list)):\n",
    "    text = p_list[i].split(':')[0]\n",
    "    perennials.append(text)\n",
    "\n",
    "# Remove mislabeled text from list of perennials\n",
    "perennials.remove('y.')\n",
    "perennials.remove('Full to part sun\\xa0 Hardy in zones ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adnophora Liliifolia',\n",
       " 'Agastache',\n",
       " 'Asiatic lily (also Oriental lily)',\n",
       " 'Aster (hardy)',\n",
       " 'Astilbe',\n",
       " 'Azalea, deciduous',\n",
       " 'Balloon Flower',\n",
       " 'Bee Balm',\n",
       " 'Bellflower',\n",
       " 'Black-Eyed Susan',\n",
       " 'Bleeding Heart',\n",
       " 'Centaurea (Perennial Cornflower)',\n",
       " 'Clematis',\n",
       " 'Chrysanthemum',\n",
       " 'Columbine',\n",
       " 'Coneflower',\n",
       " 'Coral Bells',\n",
       " 'Coreopsis',\n",
       " 'Daylilies',\n",
       " 'Delphinium',\n",
       " 'Ferns',\n",
       " 'Gaillardia (blanket flower)',\n",
       " 'Geranium, hardy',\n",
       " 'Hosta',\n",
       " 'Iris',\n",
       " 'Ladyâ€™s Mantle',\n",
       " 'Lavender',\n",
       " 'Lily of the Valley',\n",
       " 'Lungwort',\n",
       " 'Mallow',\n",
       " 'Nepeta',\n",
       " 'Penstemon',\n",
       " 'Peonies',\n",
       " 'Phlox paniculata hybrids',\n",
       " 'Phlox subulata',\n",
       " 'Pinks',\n",
       " 'Poppies',\n",
       " 'Rudbeckia',\n",
       " 'Russian Sage',\n",
       " 'Salvia',\n",
       " 'Sedum',\n",
       " 'Spotted Dead Nettle, or Lamium',\n",
       " 'Veronica (Speedwell)',\n",
       " 'Yarrow']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perennials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preen.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of weeds and\n",
    "# Scrape weed photos from preen site\n",
    "\n",
    "weed_url = 'https://www.preen.com/weeds/il'\n",
    "response = get(weed_url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "div = soup.find(id = 'WeedList')\n",
    "w_list = div.find_all('a')\n",
    "weeds = []\n",
    "for i in range(len(w_list)):\n",
    "    # Create list of weed names\n",
    "    text = w_list[i].find('img').attrs['alt']  \n",
    "    weeds.append(text)\n",
    "    \n",
    "    # Scrape photos from site\n",
    "    photo_url = 'https://www.preen.com' + w_list[i].attrs['href']\n",
    "    photo_response = get(photo_url)\n",
    "    photo_html = photo_response.text\n",
    "    photo_soup = BeautifulSoup(photo_html, 'lxml')\n",
    "    photo_div = photo_soup.find(id = 'imagePicker')\n",
    "    photo_list = photo_div.find_all('a')\n",
    "    for j in range(len(photo_list)):\n",
    "        photo_url = 'https:' + photo_list[j].attrs['href'].replace(' ', '%20')\n",
    "        \n",
    "        # To account for photos that were removed from the site\n",
    "        if get(photo_url).status_code != 404:\n",
    "            \n",
    "            # \"pr\" suffix to indicate photos were scraped from preen site\n",
    "            path = os.path.join(weed_path, text.lower().replace(' ', '_') + '_pr')\n",
    "            urllib.request.urlretrieve(photo_url, path + '_' + str(j) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of weeds and\n",
    "# Scrape weed photos from preen site\n",
    "\n",
    "weed_url = 'https://www.preen.com/weeds/il'\n",
    "response = get(weed_url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "div = soup.find(id = 'WeedList')\n",
    "w_list = div.find_all('a')\n",
    "weeds = []\n",
    "for i in range(len(w_list)):\n",
    "    # Create list of weed names\n",
    "    text = w_list[i].find('img').attrs['alt']  \n",
    "    weeds.append(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## garden.org\n",
    "I have created a function (enter_url) that provides the name of each perennial/weed one at a time.  The first prompt allows the user to skip the perennial/weed if no photos are provided for the plant on garden.org.  If photos exist, the user can enter the url for the plant.  The function scrapes all photos where the plant name is identified in the header or as a common name for the plant.  All plants are stored with the plant name as part of the name of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import traceback\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxies():\n",
    "    html = requests.get('https://free-proxy-list.net/').text\n",
    "    ip_addresses = list(pd.read_html(html)[0].query('Https == \"yes\"')['IP Address'] + ':' +\\\n",
    "        pd.read_html(html)[0].query('Https == \"yes\"')['Port'].astype(str))\n",
    "    return ip_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_addresses = get_proxies()\n",
    "proxies = cycle(ip_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProxyError",
     "evalue": "HTTPSConnectionPool(host='garden.org', port=443): Max retries exceeded with url: /plants/view/75093/Yarrow-Achillea-Moonshine/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 502 Bad Gateway')))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_new_proxy_conn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_proxy_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# self._tunnel_host below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;31m# Mark this connection as not reusable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m             raise OSError(\"Tunnel connection failed: %d %s\" % (code,\n\u001b[0m\u001b[1;32m    905\u001b[0m                                                                message.strip()))\n",
      "\u001b[0;31mOSError\u001b[0m: Tunnel connection failed: 502 Bad Gateway",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    727\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='garden.org', port=443): Max retries exceeded with url: /plants/view/75093/Yarrow-Achillea-Moonshine/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 502 Bad Gateway')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProxyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-34da63d74763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplant_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://garden.org/plants/view/75093/Yarrow-Achillea-Moonshine/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplant_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'http'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ProxyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProxyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProxyError\u001b[0m: HTTPSConnectionPool(host='garden.org', port=443): Max retries exceeded with url: /plants/view/75093/Yarrow-Achillea-Moonshine/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 502 Bad Gateway')))"
     ]
    }
   ],
   "source": [
    "# Check if plant photos appear on search result page\n",
    "plant_url = 'https://garden.org/plants/view/75093/Yarrow-Achillea-Moonshine/'\n",
    "proxy = next(proxies)\n",
    "response = requests.get(plant_url, headers = {'User-Agent' : 'test'}, proxies = {'http' : proxy, 'https' : proxy})\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup.find_all('div', {'class' : 'plant_thumbbox'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request #1\n",
      "Skipping. Connnection error\n",
      "Request #2\n",
      "{'origin': '47.57.30.255'}\n",
      "Request #3\n",
      "Skipping. Connnection error\n",
      "Request #4\n",
      "{'origin': '136.228.141.154'}\n",
      "Request #5\n",
      "Skipping. Connnection error\n",
      "Request #6\n",
      "{'origin': '92.51.11.167'}\n",
      "Request #7\n",
      "{'origin': '34.105.37.21'}\n",
      "Request #8\n",
      "{'origin': '194.233.69.41'}\n",
      "Request #9\n",
      "{'origin': '52.188.167.61'}\n",
      "Request #10\n",
      "Skipping. Connnection error\n"
     ]
    }
   ],
   "source": [
    "url = 'https://httpbin.org/ip'\n",
    "for i in range(1,11):\n",
    "    #Get a proxy from the pool\n",
    "    proxy = next(proxies)\n",
    "    print(\"Request #%d\"%i)\n",
    "    try:\n",
    "        response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
    "        print(response.json())\n",
    "    except:\n",
    "        #Most free proxies will often get connection errors. You will have retry the entire request using another proxy to work. \n",
    "        #We will just skip retries as its beyond the scope of this tutorial and we are only downloading a single url \n",
    "        print(\"Skipping. Connnection error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get soup from garden.org site\n",
    "def get_soup(url):\n",
    "    # Need to \"fake a browser visit\" by providing a user-agent header for garden.org\n",
    "    response = requests.get(url, headers = {'User-Agent' : 'test'}, proxies = {'http' : proxy, 'https' : proxy})\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    return soup\n",
    "\n",
    "# garden.org provides a \"results page\" when searching for a plant\n",
    "# Each \"result\" includes a link that provides photos for the plant\n",
    "# Function goes to the URL for each result on page, and calls the \"add_plant\" function\n",
    "def get_results(result_soup, plant_name, count, weed):\n",
    "    find_plants_results = result_soup.find('table')\n",
    "    plants_results = find_plants_results.find_all('tr')\n",
    "    # Create list of URLs for each result\n",
    "    for k in range(len(plants_results)): # For each result\n",
    "        plant_url = 'https://garden.org' + plants_results[k].find('a').attrs['href']\n",
    "        # Count keeps track of the number of photos for each plant\n",
    "        count = add_plant(plant_url, plant_name, count, weed)\n",
    "    sleep(1)\n",
    "    return (count)\n",
    "\n",
    "# Function adds all photos from each \"result\"\n",
    "# \"Results\" include plants that contain the search term\n",
    "# Only plants that match the name of the search term \n",
    "# as a \"common name\" for the plant or in the header of the page are included\n",
    "def add_plant(plant_url, plant_name, count, weed):\n",
    "    soup = get_soup(plant_url)\n",
    "    if weed:\n",
    "        path = os.path.join(weed_path, plant_name)\n",
    "    else:\n",
    "        path = os.path.join(perennial_path, plant_name)\n",
    "    \n",
    "    # Create list of common names\n",
    "    tables = soup.find_all('table')\n",
    "    common_names_table = None\n",
    "    for j in range(len(tables)):\n",
    "        if tables[j].find('caption'):\n",
    "            if 'common' in tables[j].find('caption').text.lower():\n",
    "                common_names_table = tables[j]\n",
    "    common_names_list = []\n",
    "    if common_names_table:\n",
    "        common_names = common_names_table.find_all('tr')\n",
    "        for k in range(len(common_names)):\n",
    "            common_names_list.append(common_names[k].find('td').findNextSibling().text.strip().lower())\n",
    "                \n",
    "    # Add names in header to list of common names\n",
    "    header_names = soup.find('h1', {'class' : 'page-header'}).text.lower()\n",
    "    header_names = header_names.replace('(', 'â†’').replace(')', '').split('â†’')\n",
    "    common_names_list += header_names\n",
    "    \n",
    "    # If search term is in header or list of common names, add photos\n",
    "    if plant_name.replace('_', ' ') in common_names_list:\n",
    "        photo_gallery = soup.find_all('div', {'class' : 'plant_thumbbox'})\n",
    "        for i in range(len(photo_gallery)):\n",
    "            photo_url = 'https://garden.org' + photo_gallery[i].find('a').find('img').attrs['src']\n",
    "            if get(photo_url).status_code != 404:\n",
    "                urllib.request.urlretrieve(photo_url, path + '_' + str(count) + '.jpg')\n",
    "                count += 1\n",
    "    return (count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find URLs for results page and pull all plants for each result\n",
    "# \"data\" is the list of perennials or weeds\n",
    "# \"weed\" indicates whether the plant is a weed (weed=True) or not\n",
    "def enter_url(data, weed):\n",
    "    for l in range(len(data)):\n",
    "        print('Plant:  ', data[l])\n",
    "        add_photos = input('Add Photos? (Y/N):  ')\n",
    "        if (add_photos == 'Y') or (add_photos == 'y'):\n",
    "            plants_url = input('Enter garden.org url:  ')\n",
    "            plant_name = plants_url.split('=')[-1].replace('+', '_')\n",
    "            count = 0 # Track number of results to name plant\n",
    "            \n",
    "            # Go to URL for each result on page, and add plants from each\n",
    "            plant_soup = get_soup(plants_url)\n",
    "            count = get_results(plants_soup, plant_name, count, weed)\n",
    "            \n",
    "            # Check if there are additional results pages\n",
    "            # Will return actual page if one exists. Otherwise, will return nothing.\n",
    "            query = plant_soup.find('span', {'class' : 'PageActive'})\n",
    "            if query:\n",
    "                next_page = query.findNextSibling()\n",
    "                while next_page:\n",
    "                    next_url = 'https://garden.org' + next_page.attrs['href'] # Go to next page of results\n",
    "                    plant_soup = get_soup(next_url)\n",
    "                    count = get_results(plant_soup, plant_name, count, weed)\n",
    "                    query = plant_soup.find('span', {'class' : 'PageActive'})\n",
    "                    if query:\n",
    "                        next_page = query.findNextSibling()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To call each plant separately, enter url for main results page for each plant\n",
    "\n",
    "def pull_data(plants_url, weed):\n",
    "    plant_name = plants_url.split('=')[-1].replace('+', '_')\n",
    "    count = 0 # Track number of results to name plant\n",
    "    # Go to URL for each result on page, and add plants from each\n",
    "    plant_soup = get_soup(plants_url)\n",
    "    count = get_results(plant_soup, plant_name, count, weed)\n",
    "    \n",
    "    # Check if there are additional results pages\n",
    "    # Will return actual page if one exists. Otherwise, will return nothing.\n",
    "    query = plant_soup.find('span', {'class' : 'PageActive'})\n",
    "    if query:\n",
    "        next_page = query.findNextSibling()\n",
    "        while next_page:\n",
    "            next_url = 'https://garden.org' + next_page.attrs['href'] # Go to next page of results\n",
    "            plant_soup = get_soup(next_url)\n",
    "            count = get_results(plant_soup, plant_name, count, weed)\n",
    "            query = plant_soup.find('span', {'class' : 'PageActive'})\n",
    "            if query:\n",
    "                next_page = query.findNextSibling()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_url = 'https://garden.org/plants/search/text/?q=Yarrow'\n",
    "pull_data(plants_url, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_url = 'https://garden.org/plants/view/75098/Yarrows-Achillea/'\n",
    "plant_soup = get_soup(plants_url)\n",
    "plant_name = plants_url.split('=')[-1].replace('+', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if plant photos appear on search result page\n",
    "plant_url = 'https://garden.org/plants/view/75084/Yarrow-Achillea-millefolium/'\n",
    "count = 0\n",
    "add_plant(plant_url, plant_name, count, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_url(perennials, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_url(weeds, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buckhorn plantain',\n",
       " 'bull thistle',\n",
       " 'Carolina geranium',\n",
       " 'carpetweed',\n",
       " 'catchweed bedstraw',\n",
       " 'cheat grass',\n",
       " 'chickweed',\n",
       " 'common mallow',\n",
       " 'corn speedwell',\n",
       " 'Crabgrass',\n",
       " 'crowfoot grass',\n",
       " 'curly dock',\n",
       " 'dallisgrass',\n",
       " 'dandelion',\n",
       " 'eclipta',\n",
       " 'evening primrose',\n",
       " 'fall panicum',\n",
       " 'fiddleneck',\n",
       " 'field bindweed',\n",
       " 'fleabane',\n",
       " 'giant foxtail',\n",
       " 'goosegrass',\n",
       " 'green foxtail',\n",
       " 'groundsel',\n",
       " 'hairy bittercress',\n",
       " 'hairy galinsoga',\n",
       " 'henbit',\n",
       " 'honeyvine milkweed',\n",
       " 'jimsonweed',\n",
       " 'Johnsongrass',\n",
       " 'junglerice',\n",
       " 'kochia',\n",
       " 'ladysthumb',\n",
       " 'lambsquarters',\n",
       " 'lanceleaf groundcherry',\n",
       " 'lespedeza',\n",
       " 'lovegrass',\n",
       " 'marestail',\n",
       " 'mayweed',\n",
       " 'morning glory',\n",
       " 'mustard',\n",
       " 'nettleleaf goosefoot',\n",
       " 'orchardgrass',\n",
       " 'Pennsylvania smartweed',\n",
       " 'perennial ryegrass',\n",
       " 'pineappleweed',\n",
       " 'pokeweed',\n",
       " 'prickly lettuce',\n",
       " 'prickly sida',\n",
       " 'prostrate knotweed',\n",
       " 'prostrate spurge',\n",
       " 'puncturevine',\n",
       " 'purple cudweed',\n",
       " 'purslane',\n",
       " 'ragweed',\n",
       " 'rattail fescue',\n",
       " 'red sorrel',\n",
       " 'redroot pigweed',\n",
       " 'Russian thistle',\n",
       " 'scarlet pimpernel',\n",
       " 'sheep sorrel',\n",
       " \"shepherd's purse\",\n",
       " 'sibara',\n",
       " 'signalgrass',\n",
       " 'smooth crabgrass',\n",
       " 'smutgrass',\n",
       " 'southern crabgrass',\n",
       " 'southwestern cupgrass',\n",
       " 'sow thistle',\n",
       " 'spotted spurge',\n",
       " 'sprangletop',\n",
       " 'stinging nettle',\n",
       " 'stinkgrass',\n",
       " 'sunflower',\n",
       " 'sweet clover',\n",
       " 'swinecress',\n",
       " 'tansymustard',\n",
       " 'velvetleaf',\n",
       " 'Virginia pepperweed',\n",
       " 'white clover',\n",
       " 'wild cane',\n",
       " 'wild carrot',\n",
       " 'wild oat',\n",
       " 'wild radish',\n",
       " 'witchgrass',\n",
       " 'woodsorrel',\n",
       " 'yellow foxtail']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adnophora Liliifolia',\n",
       " 'Agastache',\n",
       " 'Asiatic lily (also Oriental lily)',\n",
       " 'Aster (hardy)',\n",
       " 'Astilbe',\n",
       " 'Azalea, deciduous',\n",
       " 'Balloon Flower',\n",
       " 'Bee Balm',\n",
       " 'Bellflower',\n",
       " 'Black-Eyed Susan',\n",
       " 'Bleeding Heart',\n",
       " 'Centaurea (Perennial Cornflower)',\n",
       " 'Clematis',\n",
       " 'Chrysanthemum',\n",
       " 'Columbine',\n",
       " 'Coneflower',\n",
       " 'Coral Bells',\n",
       " 'Coreopsis',\n",
       " 'Daylilies',\n",
       " 'Delphinium',\n",
       " 'Ferns',\n",
       " 'Gaillardia (blanket flower)',\n",
       " 'Geranium, hardy',\n",
       " 'Hosta',\n",
       " 'Iris',\n",
       " 'Ladyâ€™s Mantle',\n",
       " 'Lavender',\n",
       " 'Lily of the Valley',\n",
       " 'Lungwort',\n",
       " 'Mallow',\n",
       " 'Nepeta',\n",
       " 'Penstemon',\n",
       " 'Peonies',\n",
       " 'Phlox paniculata hybrids',\n",
       " 'Phlox subulata',\n",
       " 'Pinks',\n",
       " 'Poppies',\n",
       " 'Rudbeckia',\n",
       " 'Russian Sage',\n",
       " 'Salvia',\n",
       " 'Sedum',\n",
       " 'Spotted Dead Nettle, or Lamium',\n",
       " 'Veronica (Speedwell)',\n",
       " 'Yarrow']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perennials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://garden.org/plants/view/180715/Sage-Salvia-nemorosa-Mainacht/'\n",
    "soup = get_soup(url)\n",
    "soup.find_all('div', {'class' : 'plant_thumbbox'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
